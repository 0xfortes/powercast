{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_excel_files(directory):\n",
    "    \"\"\"\n",
    "    Load all Excel files from the specified directory into a dictionary of DataFrames.\n",
    "    Returns: A dictionary where keys are file names and values are DataFrames.\n",
    "    \"\"\"\n",
    "    # List Excel files (.xlsx and .xls) in the directory\n",
    "    excel_files = [f for f in os.listdir(directory) if f.endswith(('.xlsx', '.xls'))]\n",
    "    data_frames = {}\n",
    "\n",
    "    for file in excel_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            # Read the Excel file into a DataFrame\n",
    "            df = pd.read_excel(file_path)\n",
    "            # Store DataFrame in the dictionary with the file name as the key\n",
    "            data_frames[file] = df\n",
    "            print(f\"Loaded {file} successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "    return data_frames\n",
    "\n",
    "# Specify the path to the directory containing the files (.xlsx, csv)\n",
    "directory_path = r'path_to_files_directory'\n",
    "\n",
    "# Load all files into a dictionary of DataFrames\n",
    "excel_data = load_excel_files(directory_path)\n",
    "\n",
    "# Print the keys (file names) of the loaded DataFrames\n",
    "print(\"Loaded Excel files:\", list(excel_data.keys()))\n",
    "\n",
    "# Rename the Start Date column to Date, remove 'Original resolutions' text from column names,\n",
    "# and remove the second column (End Date) from each file.\n",
    "\n",
    "def clean_dataframe_columns(data_frames):\n",
    "\n",
    "    for file, df in data_frames.items():\n",
    "        # Rename 'start date' to 'Date' (case-insensitive)\n",
    "        new_columns = {col: 'Date' for col in df.columns if col.lower() == 'start date'}\n",
    "        df.rename(columns=new_columns, inplace=True)\n",
    "        \n",
    "        # Remove 'Original resolutions' from any column names\n",
    "        cleaned_columns = {\n",
    "            col: col.replace('Original resolutions', '').replace('original resolutions', '').strip()\n",
    "            for col in df.columns\n",
    "        }\n",
    "        df.rename(columns=cleaned_columns, inplace=True)\n",
    "\n",
    "        # Remove the second column if it exists\n",
    "        if df.shape[1] > 1:\n",
    "            df.drop(df.columns[1], axis=1, inplace=True)\n",
    "\n",
    "        print(f\"Processed columns for {file}: {df.columns.tolist()}\")\n",
    "    \n",
    "    return data_frames\n",
    "\n",
    "# Process the loaded DataFrames\n",
    "excel_data_clean = clean_dataframe_columns(excel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each DataFrame in the dictionary and replace '-' with NaN\n",
    "for file, df in excel_data_clean.items():\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "    df.dropna(axis=1, how='all', inplace=True)  # Drop columns where all values are NaN\n",
    "    print(f\"Replaced '-' with NaN in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, df in excel_data_clean.items():\n",
    "    if 'Date' in df.columns:  # Ensure that the column exists\n",
    "        try:\n",
    "            print(f\"Before conversion, first 5 dates in {file}:\")\n",
    "            print(df['Date'].head())\n",
    "            \n",
    "            # Special handling for monthly and yearly files\n",
    "            if \"Month\" in file:\n",
    "                # Expecting format like \"Jan 1, 2023\"\n",
    "                df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y', errors='raise')\n",
    "                # Format as \"01/01/2023 00:00\"\n",
    "                df['Date'] = df['Date'].dt.strftime('%d/%m/%Y 00:00')\n",
    "                print(f\"Successfully formatted monthly dates in {file}\")\n",
    "            elif \"Year\" in file:\n",
    "                # Expecting format like \"Jan 1, 2023\"\n",
    "                df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y', errors='raise')\n",
    "                # Format as \"01/01/2023 00:00\"\n",
    "                df['Date'] = df['Date'].dt.strftime('%d/%m/%Y 00:00')\n",
    "                print(f\"Successfully formatted yearly dates in {file}\")\n",
    "            else:\n",
    "                # For all other files, expecting a format with time, e.g., \"Jan 1, 2023 12:00 AM\"\n",
    "                df['Date'] = pd.to_datetime(df['Date'], format='%b %d, %Y %I:%M %p', errors='raise')\n",
    "                df['Date'] = df['Date'].dt.strftime('%d/%m/%Y %H:%M')\n",
    "                print(f\"Successfully formatted dates in {file}\")\n",
    "\n",
    "            print(f\"After conversion, first 5 dates in {file}:\")\n",
    "            print(df['Date'].head())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing 'Date' column in {file}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file} does not have a 'Date' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows with empty data in all the columns\n",
    "\n",
    "for file, df in excel_data_clean.items():\n",
    "    if 'Date' in df.columns:  \n",
    "        # Drop rows where all columns (EXCEPT \"Date\") are NaN\n",
    "        df.dropna(how='all', subset=[col for col in df.columns if col != 'Date'], inplace=True)\n",
    "\n",
    "        print(f\"Cleaned empty rows in {file}. Remaining rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the data type of the data in the dfs dict\n",
    "\n",
    "for file, df in excel_data_clean.items():\n",
    "        print(\"Data types of columns:\")\n",
    "        print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, df in excel_data.items():\n",
    "        # Exclude the 'Date' column\n",
    "        cols_to_convert = [col for col in df.columns if col != 'Date']\n",
    "        \n",
    "\n",
    "        for col in cols_to_convert:\n",
    "            # Strip spaces, remove commas, and any non-numeric characters (except for decimals)\n",
    "            df[col] = df[col].replace({',': '', ' ': '', 'â‚¬': '', '%': ''}, regex=True)\n",
    "\n",
    "            # Convert the cleaned column to numeric (float)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        print(f\"Cleaned and converted columns to float for {file}\")\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the names (keys) of all DataFrames in the dictionary\n",
    "print(\"List of DataFrames in the dictionary:\")\n",
    "for file_name, df in excel_data.items():\n",
    "    print(f\"- {file_name}: {df.shape} rows x {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Check for missing values\n",
    "\n",
    "for file, df in excel_data_clean.items():\n",
    "    print(f\"Checking missing values in: {file}\")\n",
    "    print(df.isnull().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, df in excel_data_clean.items():\n",
    "    if 'Date' in df.columns:\n",
    "        try:\n",
    "            # Parse the 'Date' column using your specific format.\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y %H:%M\", dayfirst=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error parsing dates in {file}: {e}\")\n",
    "        \n",
    "        # Verify that no dates failed to parse.\n",
    "        if df['Date'].isna().any():\n",
    "            raise ValueError(f\"Some dates in {file} could not be parsed.\")\n",
    "        \n",
    "        # Set the 'Date' column as the index\n",
    "        df.set_index('Date', inplace=True)\n",
    "    else:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "            print(f\"File {file} is missing a valid 'Date' column and its index is not datetime.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"File {file} already has a datetime index.\")\n",
    "\n",
    "    # Resampling logic based on file naming convention\n",
    "    if file.endswith('Quarterhour.xlsx'):\n",
    "        # Aggregate quarter-hourly data to hourly using sum\n",
    "        df = df.resample('h').sum()  # using lowercase 'h'\n",
    "        print(f\"Aggregated {file} from quarter-hourly to hourly (using sum).\")\n",
    "    elif file.endswith('Year.xlsx') or file.endswith('Month.xlsx'):\n",
    "        # Disaggregate monthly/yearly data to hourly by forward-filling the value\n",
    "        df = df.resample('h').ffill()\n",
    "        print(f\"Disaggregated {file} from {file[-8:-4]} to hourly (using forward fill).\")\n",
    "    elif file.endswith('Hour.xlsx'):\n",
    "        # File is already hourly data; no resampling is needed.\n",
    "        print(f\"Using {file} as hourly data.\")\n",
    "    else:\n",
    "        print(f\"File {file} does not match\")\n",
    "    \n",
    "    # Interpolate missing numeric values using linear interpolation\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method='linear', axis=0)\n",
    "    print(f\"Interpolated missing values in {file}\")\n",
    " \n",
    "    \n",
    "    # Reset the index so that 'Date' becomes a column again:\n",
    "    df.reset_index(inplace=True)\n",
    "    excel_data_clean[file] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine the suffix based on the file name.\n",
    "def get_suffix(file_name):\n",
    "    if \"Actual_consumption\" in file_name:\n",
    "        return \"_actual_cons\"\n",
    "    elif \"Forecasted_consumption\" in file_name:\n",
    "        return \"_forecast_cons\"\n",
    "    elif \"Actual_generation\" in file_name:\n",
    "        return \"_actual_gen\"\n",
    "    elif \"Forecasted_generation_Day-Ahead\" in file_name:\n",
    "        return \"_forecast_dayahead_gen\"\n",
    "    elif \"Generation_Forecast_Intraday\" in file_name:\n",
    "        return \"_intraday_gen\"\n",
    "    elif \"Automatic_Frequency_Restoration_Reserve\" in file_name:\n",
    "        return \"_auto_FRR\"\n",
    "    elif \"Manual_Frequency_Restoration_Reserve\" in file_name:\n",
    "        return \"_manual_FRR\"\n",
    "    elif \"Balancing_energy\" in file_name:\n",
    "        return \"_balancing_energy\"\n",
    "    elif \"Costs_of_TSOs__without_costs_of_DSOs__\" in file_name:\n",
    "        return \"_costs_TSO\"\n",
    "    elif \"Cross-border_physical_flows\" in file_name:\n",
    "        return \"_cross_border\"\n",
    "    elif \"Day-ahead_prices\" in file_name:\n",
    "        return \"_dayahead\"\n",
    "    elif \"Exported_balancing_services\" in file_name:\n",
    "        return \"_exported_balancing\"\n",
    "    elif \"Imported_balancing_services\" in file_name:\n",
    "        return \"_imported_balancing\"\n",
    "    elif \"Frequency_Containment_Reserve\" in file_name:\n",
    "        return \"_FCR\"\n",
    "    elif \"Installed_generation_capacity\" in file_name:\n",
    "        return \"_installed_gen_cap\"\n",
    "    elif \"Scheduled_commercial_exchanges\" in file_name:\n",
    "        return \"_scheduled_exchanges\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# First, rename columns in each DataFrame (excluding the Date column) based on the file name.\n",
    "for file, df in excel_data_clean.items():\n",
    "    suffix = get_suffix(file)\n",
    "    rename_mapping = {}\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'date':\n",
    "            continue  \n",
    "        rename_mapping[col] = col + suffix\n",
    "    df.rename(columns=rename_mapping, inplace=True)\n",
    "    \n",
    "\n",
    "    print(f\"Columns in {file} after renaming:\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "# Dictionary to collect columns and the corresponding file names.\n",
    "columns_files = {}\n",
    "\n",
    "for file, df in excel_data_clean.items():\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'date':\n",
    "            continue\n",
    "        columns_files.setdefault(col, []).append(file)\n",
    "\n",
    "# Print out columns that appear in more than one file.\n",
    "print(\"Columns (excluding 'Date') that appear in multiple files:\")\n",
    "for col, files in columns_files.items():\n",
    "    if len(files) > 1:\n",
    "        print(f\"Column '{col}' appears in the following files:\")\n",
    "        for f in files:\n",
    "            print(f\"  - {f}\")\n",
    "        print()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = r'path_to_output'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for file, df in excel_data_clean.items():\n",
    "\n",
    "    processed_filename = f\"{file}\"\n",
    "    \n",
    "    # Define the output path\n",
    "    output_path = os.path.join(output_dir, processed_filename)\n",
    "    \n",
    "    # Save DataFrame as Excel file\n",
    "    df.to_excel(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved {processed_filename} to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
