{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# PowerCast: Electricity Price Forecasting Challenge - EDA Script\n",
    "#\n",
    "# This script performs exploratory data analysis (EDA) for the project.\n",
    "# It loads all datasets, performs initial inspections, and visualizes trends,\n",
    "# correlations, and lag effects that will help us to answer the challenge questions:\n",
    "#\n",
    "# 1. Market Trends & Price Fluctuations\n",
    "# 2. Correlation & Feature Relationships\n",
    "# 3. Price & Consumption Impact Analysis\n",
    "# ==================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from math import sqrt\n",
    "\n",
    "# =============================================================================\n",
    "# SETTINGS & PLOTTING STYLE\n",
    "# =============================================================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 7)\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTION: Load Excel File and Set Date Index\n",
    "# =============================================================================\n",
    "\n",
    "def load_file(file_path, date_col='Date'):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df.set_index(date_col, inplace=True)\n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# Load Datasets\n",
    "# =============================================================================\n",
    "\n",
    "# Adjust these file paths as needed.\n",
    "prices_path = r'path/tofile'\n",
    "actual_cons_path = r'path/tofile'\n",
    "forecast_cons_path = r'path/tofile'\n",
    "actual_gen_path = r'path/tofile'\n",
    "forecast_gen_da_path = r'path/tofile'\n",
    "gen_forecast_intraday_path = r'path/tofile'\n",
    "cross_border_path = r'path/tofile'\n",
    "scheduled_exchanges_path = r'path/tofile'\n",
    "imported_balancing_path = r'path/tofile'\n",
    "exported_balancing_path = r'path/tofile'\n",
    "balancing_energy_path = r'path/tofile'\n",
    "costs_path = r'path/tofile' #costs of TSOs\n",
    "auto_frr_path = r'path/tofile' #automatic frequency restoration reserve\n",
    "fcr_path = r'path/tofile' #freq containment reserve\n",
    "\n",
    "df_prices = load_file(prices_path)\n",
    "df_actual_cons = load_file(actual_cons_path)\n",
    "df_forecast_cons = load_file(forecast_cons_path)\n",
    "df_actual_gen = load_file(actual_gen_path)\n",
    "df_forecast_gen_da = load_file(forecast_gen_da_path)\n",
    "df_gen_forecast_intraday = load_file(gen_forecast_intraday_path)\n",
    "df_cross_border = load_file(cross_border_path)\n",
    "df_scheduled_exchanges = load_file(scheduled_exchanges_path)\n",
    "df_imported_balancing = load_file(imported_balancing_path)\n",
    "df_exported_balancing = load_file(exported_balancing_path)\n",
    "df_balancing_energy = load_file(balancing_energy_path)\n",
    "df_costs = load_file(costs_path)\n",
    "df_auto_frr = load_file(auto_frr_path)\n",
    "df_fcr = load_file(fcr_path)\n",
    "\n",
    "# Quick inspection of key DataFrames \n",
    "print(\"Day-Ahead Prices (first 5 rows):\")\n",
    "print(df_prices.head())\n",
    "print(\"\\nActual Consumption (first 5 rows):\")\n",
    "print(df_actual_cons.head())\n",
    "print(\"\\nForecasted Consumption (first 5 rows):\")\n",
    "print(df_forecast_cons.head())\n",
    "\n",
    "# Hourly Trends for Day-Ahead Prices\n",
    "# Hourly trends across different countries)\n",
    "\n",
    "# Select all columns containing \"dayahead\" (Chartx will be too noisy)\n",
    "all_price_cols = [col for col in df_prices.columns if \"dayahead\" in col.lower()]\n",
    "selected_price_cols = [col for col in all_price_cols if \"neighbours\" not in col.lower()]\n",
    "\n",
    "print(\"Selected day-ahead price columns (excluding neighbours):\")\n",
    "for col in selected_price_cols:\n",
    "    print(\" -\", col)\n",
    "\n",
    "# Hourly Plot \n",
    "plt.figure()\n",
    "for col in selected_price_cols:\n",
    "    plt.plot(df_prices.index, df_prices[col], label=col)\n",
    "plt.title(\"Hourly Day-Ahead Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.legend(ncol=2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Daily Trends for Day-Ahead Prices \n",
    "df_prices_daily = df_prices[selected_price_cols].resample('D').mean()\n",
    "plt.figure()\n",
    "for col in selected_price_cols:\n",
    "    plt.plot(df_prices_daily.index, df_prices_daily[col], label=col)\n",
    "plt.title(\"Daily Average Day-Ahead Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Price (€/MWh)\")\n",
    "plt.legend(ncol=2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Weekly Trends for Day-Ahead Prices \n",
    "df_prices_weekly = df_prices[selected_price_cols].resample('W').mean()\n",
    "plt.figure()\n",
    "for col in selected_price_cols:\n",
    "    plt.plot(df_prices_weekly.index, df_prices_weekly[col], label=col)\n",
    "plt.title(\"Weekly Average Day-Ahead Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Price (€/MWh)\")\n",
    "plt.legend(ncol=2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Consumption data on Prices\n",
    "# Relationship between consumption and price fluctuations\n",
    "if (\"Germany/Luxembourg [€/MWh]_dayahead\" in df_prices.columns and \n",
    "    \"Total (grid load) [MWh]_actual_cons\" in df_actual_cons.columns and \n",
    "    \"Residual load [MWh]_actual_cons\" in df_actual_cons.columns):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(14, 10))\n",
    "\n",
    "    # Day-Ahead Price\n",
    "    axes[0].plot(df_prices.index, df_prices[\"Germany/Luxembourg [€/MWh]_dayahead\"], color='blue')\n",
    "    axes[0].set_ylabel(\"Price (€/MWh)\", color='blue')\n",
    "    axes[0].tick_params(axis='y', labelcolor='blue')\n",
    "    axes[0].set_title(\"Day-Ahead Price, Actual Consumption, and Residual Load\")\n",
    "    axes[0].set_ylim(0, 450)\n",
    "\n",
    "    # Actual Consumption\n",
    "    axes[1].plot(df_actual_cons.index, df_actual_cons[\"Total (grid load) [MWh]_actual_cons\"], color='red')\n",
    "    axes[1].set_ylabel(\"Actual Consumption (MWh)\", color='red')\n",
    "    axes[1].tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "    # Residual Load\n",
    "    axes[2].plot(df_actual_cons.index, df_actual_cons[\"Residual load [MWh]_actual_cons\"], color='green')\n",
    "    axes[2].set_ylabel(\"Residual Load (MWh)\", color='green')\n",
    "    axes[2].tick_params(axis='y', labelcolor='green')\n",
    "    axes[2].set_xlabel(\"Date\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Consumption: Actual vs. Forecasted \n",
    "if \"Total (grid load) [MWh]_actual_cons\" in df_actual_cons.columns and \"Total (grid load) [MWh]_forecast_cons\" in df_forecast_cons.columns:\n",
    "    df_consumption = pd.DataFrame({\n",
    "        \"Actual\": df_actual_cons[\"Total (grid load) [MWh]_actual_cons\"],\n",
    "        \"Forecast\": df_forecast_cons[\"Total (grid load) [MWh]_forecast_cons\"]\n",
    "    })\n",
    "    df_consumption[\"Difference\"] = df_consumption[\"Actual\"] - df_consumption[\"Forecast\"]\n",
    "    df_consumption_daily = df_consumption.resample('D').mean()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(df_consumption_daily.index, df_consumption_daily[\"Actual\"], label=\"Actual Consumption\")\n",
    "    plt.plot(df_consumption_daily.index, df_consumption_daily[\"Forecast\"], label=\"Forecasted Consumption\")\n",
    "    plt.plot(df_consumption_daily.index, df_consumption_daily[\"Difference\"], label=\"Difference\", linestyle=\"--\")\n",
    "    plt.title(\"Daily Consumption: Actual vs. Forecasted\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Consumption (MWh)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Visualization for Aggregated Trends with Seasonal Highlights\n",
    "# =============================================================================\n",
    "\n",
    "# Resample daily data from the hourly prices \n",
    "df_prices_daily = df_prices[selected_price_cols].resample('D').mean()\n",
    "\n",
    "# Compute average and median\n",
    "df_prices_daily['Overall_Average'] = df_prices_daily.mean(axis=1)\n",
    "df_prices_daily['Overall_Median'] = df_prices_daily.median(axis=1)\n",
    "\n",
    "# 7-day moving average of the overall average\n",
    "df_prices_daily['Overall_Average_MA7'] = df_prices_daily['Overall_Average'].rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_prices_daily.index, df_prices_daily['Overall_Average'], \n",
    "         label='Overall Daily Average', color='blue', alpha=0.7)\n",
    "plt.plot(df_prices_daily.index, df_prices_daily['Overall_Average_MA7'], \n",
    "         label='7-Day Moving Average', color='red', linewidth=2)\n",
    "\n",
    "# Add seasonal highlights\n",
    "unique_years = sorted(df_prices_daily.index.year.unique())\n",
    "for year in unique_years:\n",
    "    summer_start = pd.Timestamp(year=year, month=6, day=20)\n",
    "    summer_end = pd.Timestamp(year=year, month=9, day=23)\n",
    "    winter_start_jan = pd.Timestamp(year=year, month=1, day=1)\n",
    "    winter_end_mar = pd.Timestamp(year=year, month=3, day=20)\n",
    "    winter_start_dec = pd.Timestamp(year=year, month=12, day=21)\n",
    "    winter_end_dec = pd.Timestamp(year=year, month=12, day=31)\n",
    "    \n",
    "    if df_prices_daily.index.min() <= summer_start <= df_prices_daily.index.max():\n",
    "        plt.axvspan(summer_start, summer_end, color='yellow', alpha=0.2)\n",
    "    if df_prices_daily.index.min() <= winter_start_jan <= df_prices_daily.index.max():\n",
    "        plt.axvspan(winter_start_jan, winter_end_mar, color='lightblue', alpha=0.2)\n",
    "    if df_prices_daily.index.min() <= winter_start_dec <= df_prices_daily.index.max():\n",
    "        plt.axvspan(winter_start_dec, winter_end_dec, color='lightblue', alpha=0.2)\n",
    "\n",
    "# Create legend patches for seasons and line objects for the averages\n",
    "summer_patch = mpatches.Patch(color='yellow', alpha=0.2, label='Summer (Jun 20 – Sep 23)')\n",
    "winter_patch = mpatches.Patch(color='lightblue', alpha=0.2, label='Winter (Dec 21 – Mar 20)')\n",
    "line_daily = plt.Line2D([], [], color='blue', label='Overall Daily Average')\n",
    "line_ma7 = plt.Line2D([], [], color='red', label='7-Day Moving Average')\n",
    "\n",
    "plt.grid(True, axis='y')\n",
    "plt.title(\"Aggregated Daily Average Day-Ahead Prices with Seasonal Highlights\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.legend(handles=[summer_patch, winter_patch, line_daily, line_ma7], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot: Distribution of Daily Overall Average Prices by Weekday\n",
    "df_prices_daily['Weekday'] = df_prices_daily.index.day_name()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(\n",
    "    x='Weekday', \n",
    "    y='Overall_Average', \n",
    "    data=df_prices_daily.reset_index(),\n",
    "    order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "    palette='pastel'\n",
    ")\n",
    "plt.title(\"Distribution of Daily Overall Average Prices by Weekday\")\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 1. Overall Hourly Average: the mean across all countries per hour.\n",
    "# 2. 24-Hour Moving Average: smooths out short-term fluctuations.\n",
    "df_prices_hourly = df_prices[selected_price_cols].copy()\n",
    "df_prices_hourly['Overall_Hourly_Average'] = df_prices_hourly.mean(axis=1)\n",
    "df_prices_hourly['Rolling_24h_Average'] = df_prices_hourly['Overall_Hourly_Average'].rolling(window=24).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_prices_hourly.index, df_prices_hourly['Overall_Hourly_Average'], \n",
    "         label='Overall Hourly Average', color='blue', alpha=0.7)\n",
    "plt.plot(df_prices_hourly.index, df_prices_hourly['Rolling_24h_Average'], \n",
    "         label='24-Hour Moving Average', color='red', linewidth=2)\n",
    "\n",
    "# Add seasonal highlights for each year\n",
    "unique_years = sorted(df_prices_hourly.index.year.unique())\n",
    "for year in unique_years:\n",
    "    summer_start = pd.Timestamp(year=year, month=6, day=20)\n",
    "    summer_end   = pd.Timestamp(year=year, month=9, day=23)\n",
    "    winter_start_jan = pd.Timestamp(year=year, month=1, day=1)\n",
    "    winter_end_mar   = pd.Timestamp(year=year, month=3, day=20)\n",
    "    winter_start_dec = pd.Timestamp(year=year, month=12, day=21)\n",
    "    winter_end_dec   = pd.Timestamp(year=year, month=12, day=31)\n",
    "    \n",
    "    if df_prices_hourly.index.min() <= summer_start <= df_prices_hourly.index.max():\n",
    "        plt.axvspan(summer_start, summer_end, color='yellow', alpha=0.2)\n",
    "    if df_prices_hourly.index.min() <= winter_start_jan <= df_prices_hourly.index.max():\n",
    "        plt.axvspan(winter_start_jan, winter_end_mar, color='lightblue', alpha=0.2)\n",
    "    if df_prices_hourly.index.min() <= winter_start_dec <= df_prices_hourly.index.max():\n",
    "        plt.axvspan(winter_start_dec, winter_end_dec, color='lightblue', alpha=0.2)\n",
    "\n",
    "# Create legend patches for seasons and lines for the hourly averages\n",
    "summer_patch = mpatches.Patch(color='yellow', alpha=0.2, label='Summer (Jun 20 – Sep 23)')\n",
    "winter_patch = mpatches.Patch(color='lightblue', alpha=0.2, label='Winter (Dec 21 – Mar 20)')\n",
    "line_hourly = plt.Line2D([], [], color='blue', label='Overall Hourly Average')\n",
    "line_24h = plt.Line2D([], [], color='red', label='24-Hour Moving Average')\n",
    "\n",
    "plt.legend(handles=[summer_patch, winter_patch, line_hourly, line_24h], loc='upper left')\n",
    "plt.grid(True, axis='y')\n",
    "plt.title(\"Aggregated Hourly Average Day-Ahead Prices with Seasonal Highlights\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# To better understand the distribution of prices per hour, I added a boxplot grouping by the hour of the day.\n",
    "df_prices_hourly['Hour'] = df_prices_hourly.index.hour  \n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(\n",
    "    x='Hour',\n",
    "    y='Overall_Hourly_Average',\n",
    "    data=df_prices_hourly.reset_index(),  \n",
    "    color='lightblue'\n",
    ")\n",
    "plt.title(\"Distribution of Hourly Prices by Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day (0-23)\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resample weekly data from hourly prices\n",
    "df_prices_weekly = df_prices[selected_price_cols].resample('W').mean()\n",
    "\n",
    "# Compute average and median  for weekly data\n",
    "df_prices_weekly['Overall_Average'] = df_prices_weekly.mean(axis=1)\n",
    "df_prices_weekly['Overall_Median'] = df_prices_weekly.median(axis=1)\n",
    "# Apply a smoothing window: 4-week moving average\n",
    "df_prices_weekly['Overall_Average_MA4'] = df_prices_weekly['Overall_Average'].rolling(window=4).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_prices_weekly.index, df_prices_weekly['Overall_Average'], \n",
    "         label='Overall Weekly Average', color='blue', alpha=0.7)\n",
    "plt.plot(df_prices_weekly.index, df_prices_weekly['Overall_Average_MA4'], \n",
    "         label='4-Week Moving Average', color='red', linewidth=2)\n",
    "\n",
    "# Loop over each unique year for seasonal highlights\n",
    "unique_years = sorted(df_prices_weekly.index.year.unique())\n",
    "for year in unique_years:\n",
    "    summer_start = pd.Timestamp(year=year, month=6, day=20)\n",
    "    summer_end = pd.Timestamp(year=year, month=9, day=23)\n",
    "    winter_start_jan = pd.Timestamp(year=year, month=1, day=1)\n",
    "    winter_end_mar = pd.Timestamp(year=year, month=3, day=20)\n",
    "    winter_start_dec = pd.Timestamp(year=year, month=12, day=21)\n",
    "    winter_end_dec = pd.Timestamp(year=year, month=12, day=31)\n",
    "    \n",
    "    if df_prices_weekly.index.min() <= summer_start <= df_prices_weekly.index.max():\n",
    "        plt.axvspan(summer_start, summer_end, color='yellow', alpha=0.2)\n",
    "    if df_prices_weekly.index.min() <= winter_start_jan <= df_prices_weekly.index.max():\n",
    "        plt.axvspan(winter_start_jan, winter_end_mar, color='lightblue', alpha=0.2)\n",
    "    if df_prices_weekly.index.min() <= winter_start_dec <= df_prices_weekly.index.max():\n",
    "        plt.axvspan(winter_start_dec, winter_end_dec, color='lightblue', alpha=0.2)\n",
    "\n",
    "# Create legend patches for seasons and line objects for weekly averages\n",
    "summer_patch = mpatches.Patch(color='yellow', alpha=0.2, label='Summer (Jun 20 – Sep 23)')\n",
    "winter_patch = mpatches.Patch(color='lightblue', alpha=0.2, label='Winter (Dec 21 – Mar 20)')\n",
    "line_weekly = plt.Line2D([], [], color='blue', label='Overall Weekly Average')\n",
    "line_ma4 = plt.Line2D([], [], color='red', label='4-Week Moving Average')\n",
    "\n",
    "plt.grid(True, axis='y')\n",
    "plt.title(\"Aggregated Weekly Average Day-Ahead Prices with Seasonal Highlights\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.legend(handles=[summer_patch, winter_patch, line_weekly, line_ma4], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Electricity Generation vs. Price Trends Analysis\n",
    "# =============================================================================\n",
    "\n",
    "# --- Feature Engineering for Generation Data ---\n",
    "\n",
    "# For Actual Generation: Sum all the actual generation columns to get a Total_Gen.\n",
    "# The columns in df_actual_gen end with '_actual_gen'\n",
    "actual_gen_cols = [col for col in df_actual_gen.columns if '_actual_gen' in col.lower()]\n",
    "df_actual_gen['Total_Gen'] = df_actual_gen[actual_gen_cols].sum(axis=1)\n",
    "\n",
    "# For Forecasted Generation: Use the total forecast column.\n",
    "# Note: There are redundant columns, so we choose \"Total [MWh]_forecast_dayahead_gen\".\n",
    "df_forecast_gen_da['Total_Gen_Forecast'] = df_forecast_gen_da[\"Total [MWh]_forecast_dayahead_gen\"]\n",
    "\n",
    "# Resample the generation data to daily frequency.\n",
    "df_actual_gen_daily = df_actual_gen['Total_Gen'].resample('D').sum()\n",
    "df_forecast_gen_daily = df_forecast_gen_da['Total_Gen_Forecast'].resample('D').sum()\n",
    "\n",
    "\n",
    "# Dual Axis Time Series Plot\n",
    "# This plot shows daily overall price (left y-axis) and generation (right y-axis).\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot Overall Daily Price on the left y-axis\n",
    "line1, = ax1.plot(df_prices_daily.index, df_prices_daily['Overall_Average'], \n",
    "                  label=\"Overall Daily Price\", color='blue', linewidth=2)\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Price (€/MWh)\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Remove vertical gridlines, and keep horizontal gridlines only on ax1\n",
    "ax1.grid(True, which='both', axis='y')\n",
    "ax1.grid(False, which='both', axis='x')\n",
    "\n",
    "# Create a second y-axis for generation data, and disable its gridlines\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(df_actual_gen_daily.index, df_actual_gen_daily, \n",
    "                  label=\"Actual Generation\", color='green', linestyle='-', linewidth=2)\n",
    "line3, = ax2.plot(df_forecast_gen_daily.index, df_forecast_gen_daily, \n",
    "                  label=\"Forecast Generation\", color='orange', linestyle='--', linewidth=2)\n",
    "ax2.set_ylabel(\"Generation (MWh)\", color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "ax2.grid(False)\n",
    "\n",
    "# Combine legends from both axes and place outside the chart on the right\n",
    "lines = [line1, line2, line3]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n",
    "\n",
    "plt.title(\"Daily Electricity Price and Generation (Actual vs. Forecast)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot of Generation Error vs. Price \n",
    "# Compute generation error (Actual - Forecast)\n",
    "df_gen_error = pd.DataFrame({\n",
    "    \"Actual\": df_actual_gen_daily,\n",
    "    \"Forecast\": df_forecast_gen_daily\n",
    "})\n",
    "df_gen_error[\"Error\"] = df_gen_error[\"Actual\"] - df_gen_error[\"Forecast\"]\n",
    "\n",
    "# For alignment, I also extract the corresponding daily price values.\n",
    "common_dates = df_gen_error.index.intersection(df_prices_daily.index)\n",
    "error = df_gen_error.loc[common_dates, \"Error\"]\n",
    "price = df_prices_daily.loc[common_dates, \"Overall_Average\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=error, y=price, color='purple', alpha=0.7)\n",
    "plt.xlabel(\"Generation Error (Actual - Forecast) (MWh)\")\n",
    "plt.ylabel(\"Overall Daily Price (€/MWh)\")\n",
    "plt.title(\"Scatter Plot of Generation Error vs. Price\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Electricity Generation vs. Price Trends: Split Analysis \n",
    "# =============================================================================\n",
    "\n",
    "# Feature Engineering for Actual Generation\n",
    "\n",
    "# Renewable generation: Sum of Biomass, Hydropower, Wind offshore, Wind onshore,\n",
    "# Photovoltaics, and Other renewable.\n",
    "renewable_cols_actual = [\n",
    "    \"Biomass [MWh]_actual_gen\", \"Hydropower [MWh]_actual_gen\",\n",
    "    \"Wind offshore [MWh]_actual_gen\", \"Wind onshore [MWh]_actual_gen\",\n",
    "    \"Photovoltaics [MWh]_actual_gen\", \"Other renewable [MWh]_actual_gen\"\n",
    "]\n",
    "df_actual_gen[\"Renewables_Actual\"] = df_actual_gen[renewable_cols_actual].sum(axis=1)\n",
    "\n",
    "# Conventional generation: Sum of Nuclear, Lignite, Hard coal, Fossil gas,\n",
    "# Hydro pumped storage, and Other conventional.\n",
    "conventional_cols_actual = [\n",
    "    \"Nuclear [MWh]_actual_gen\", \"Lignite [MWh]_actual_gen\",\n",
    "    \"Hard coal [MWh]_actual_gen\", \"Fossil gas [MWh]_actual_gen\",\n",
    "    \"Hydro pumped storage [MWh]_actual_gen\", \"Other conventional [MWh]_actual_gen\"\n",
    "]\n",
    "df_actual_gen[\"Conventional_Actual\"] = df_actual_gen[conventional_cols_actual].sum(axis=1)\n",
    "\n",
    "# Feature Engineering for Forecasted Generation \n",
    "\n",
    "# - Renewables: \"Photovoltaics and wind [MWh]_forecast_dayahead_gen\"\n",
    "# - Conventional: \"Other [MWh]_forecast_dayahead_gen\" (instead of the total)\n",
    "df_forecast_gen_da[\"Renewables_Forecast\"] = df_forecast_gen_da[\"Photovoltaics and wind [MWh]_forecast_dayahead_gen\"]\n",
    "df_forecast_gen_da[\"Conventional_Forecast\"] = df_forecast_gen_da[\"Other [MWh]_forecast_dayahead_gen\"]\n",
    "\n",
    "# Resample Generation Data to Daily \n",
    "df_actual_gen_daily = df_actual_gen[[\"Renewables_Actual\", \"Conventional_Actual\"]].resample('D').sum()\n",
    "df_forecast_gen_daily = df_forecast_gen_da[[\"Renewables_Forecast\", \"Conventional_Forecast\"]].resample('D').sum()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Figure 1: Renewables vs. Price Trends \n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(14, 10))\n",
    "\n",
    "# Overall Daily Price\n",
    "axes[0].plot(df_prices_daily.index, df_prices_daily['Overall_Average'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel(\"Price (€/MWh)\")\n",
    "axes[0].set_title(\"Overall Daily Price\")\n",
    "axes[0].grid(True, which='both', axis='y')\n",
    "axes[0].grid(False, which='both', axis='x')\n",
    "\n",
    "# Actual Renewables Generation\n",
    "axes[1].plot(df_actual_gen_daily.index, df_actual_gen_daily[\"Renewables_Actual\"], color='green', linewidth=2)\n",
    "axes[1].set_ylabel(\"Actual Renewables (MWh)\")\n",
    "axes[1].set_title(\"Actual Renewables Generation\")\n",
    "axes[1].grid(True, which='both', axis='y')\n",
    "axes[1].grid(False, which='both', axis='x')\n",
    "\n",
    "# Forecast Renewables Generation\n",
    "axes[2].plot(df_forecast_gen_daily.index, df_forecast_gen_daily[\"Renewables_Forecast\"], \n",
    "             color='orange', linestyle='--', linewidth=2)\n",
    "axes[2].set_ylabel(\"Forecast Renewables (MWh)\")\n",
    "axes[2].set_title(\"Forecast Renewables Generation\")\n",
    "axes[2].set_xlabel(\"Date\")\n",
    "axes[2].grid(True, which='both', axis='y')\n",
    "axes[2].grid(False, which='both', axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Figure 2: Conventional Generation vs. Price Trends \n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(14, 10))\n",
    "\n",
    "# Overall Daily Price\n",
    "axes[0].plot(df_prices_daily.index, df_prices_daily['Overall_Average'], color='blue', linewidth=2)\n",
    "axes[0].set_ylabel(\"Price (€/MWh)\")\n",
    "axes[0].set_title(\"Overall Daily Price\")\n",
    "axes[0].grid(True, which='both', axis='y')\n",
    "axes[0].grid(False, which='both', axis='x')\n",
    "\n",
    "# Actual Conventional Generation\n",
    "axes[1].plot(df_actual_gen_daily.index, df_actual_gen_daily[\"Conventional_Actual\"], color='green', linewidth=2)\n",
    "axes[1].set_ylabel(\"Actual Conventional (MWh)\")\n",
    "axes[1].set_title(\"Actual Conventional Generation\")\n",
    "axes[1].grid(True, which='both', axis='y')\n",
    "axes[1].grid(False, which='both', axis='x')\n",
    "\n",
    "# Forecast Conventional Generation\n",
    "axes[2].plot(df_forecast_gen_daily.index, df_forecast_gen_daily[\"Conventional_Forecast\"], \n",
    "             color='orange', linestyle='--', linewidth=2)\n",
    "axes[2].set_ylabel(\"Forecast Conventional (MWh)\")\n",
    "axes[2].set_title(\"Forecast Conventional Generation\")\n",
    "axes[2].set_xlabel(\"Date\")\n",
    "axes[2].grid(True, which='both', axis='y')\n",
    "axes[2].grid(False, which='both', axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Cross-border Physical Flows vs. Scheduled Commercial Exchanges Analysis\n",
    "# =============================================================================\n",
    "# In this section, we merge the scheduled and cross-border datasets on the Date index\n",
    "\n",
    "# We focus on the \"Net export\" columns.\n",
    "df_flows = pd.merge(\n",
    "    df_scheduled_exchanges[['Net export [MWh]_scheduled_exchanges']],\n",
    "    df_cross_border[['Net export [MWh]_cross_border']],\n",
    "    left_index=True, right_index=True, how='inner'\n",
    ")\n",
    "\n",
    "# Compute the difference and percentage difference between scheduled and cross-border flows.\n",
    "df_flows['Difference'] = (df_flows['Net export [MWh]_scheduled_exchanges'] -\n",
    "                          df_flows['Net export [MWh]_cross_border'])\n",
    "df_flows['Perc_Difference'] = (df_flows['Difference'] /\n",
    "                               df_flows['Net export [MWh]_scheduled_exchanges']) * 100\n",
    "\n",
    "# Time Series of Scheduled vs. Cross-border Net Exports \n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_flows.index, df_flows['Net export [MWh]_scheduled_exchanges'], \n",
    "         label='Scheduled Net Export', linewidth=2)\n",
    "plt.plot(df_flows.index, df_flows['Net export [MWh]_cross_border'], \n",
    "         label='Cross-border Net Export', linewidth=2)\n",
    "plt.title(\"Scheduled vs. Cross-border Net Exports Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Net Export (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time Series of the Difference (Scheduled - Cross-border)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_flows.index, df_flows['Difference'], color='red', \n",
    "         label='Difference (Scheduled - Cross-border)', linewidth=2)\n",
    "plt.title(\"Difference Between Scheduled and Cross-border Net Exports\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Difference (MWh)\")\n",
    "plt.ylim(-4500, 4000)  # Set the y-axis limits to -50 and 50, adjust as needed\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot of Scheduled vs. Cross-border Net Exports\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Net export [MWh]_scheduled_exchanges', \n",
    "                y='Net export [MWh]_cross_border', \n",
    "                data=df_flows, color='purple', alpha=0.7)\n",
    "# Add a reference line (45°) to assess the agreement between the two measures\n",
    "min_val = df_flows['Net export [MWh]_scheduled_exchanges'].min()\n",
    "max_val = df_flows['Net export [MWh]_scheduled_exchanges'].max()\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--', label='45° Line')\n",
    "plt.title(\"Scatter Plot: Scheduled vs. Cross-border Net Exports\")\n",
    "plt.xlabel(\"Scheduled Net Export (MWh)\")\n",
    "plt.ylabel(\"Cross-border Net Export (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7-Day Moving Averages for Smoothing Trends\n",
    "df_flows['Scheduled_MA7'] = df_flows['Net export [MWh]_scheduled_exchanges'].rolling(window=7).mean()\n",
    "df_flows['CrossBorder_MA7'] = df_flows['Net export [MWh]_cross_border'].rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_flows.index, df_flows['Scheduled_MA7'], \n",
    "         label='Scheduled Net Export 7-Day MA', linewidth=2)\n",
    "plt.plot(df_flows.index, df_flows['CrossBorder_MA7'], \n",
    "         label='Cross-border Net Export 7-Day MA', linewidth=2)\n",
    "plt.title(\"7-Day Moving Average: Scheduled vs. Cross-border Net Exports\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Net Export (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# Aggregating Exports and Imports for Scheduled Exchanges and Cross-Border Flows\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Identify export columns \n",
    "export_cols_sched = [col for col in df_scheduled_exchanges.columns if \"(export)\" in col.lower()]\n",
    "# Identify import columns \n",
    "import_cols_sched = [col for col in df_scheduled_exchanges.columns if \"(import)\" in col.lower()]\n",
    "\n",
    "# Compute the total exports and imports per row.\n",
    "df_scheduled_exchanges['Total_Exports_scheduled'] = df_scheduled_exchanges[export_cols_sched].sum(axis=1)\n",
    "df_scheduled_exchanges['Total_Imports_scheduled'] = df_scheduled_exchanges[import_cols_sched].sum(axis=1)\n",
    "\n",
    "\n",
    "# For Cross-Border Physical Flows\n",
    "export_cols_cross = [col for col in df_cross_border.columns if \"(export)\" in col.lower()]\n",
    "import_cols_cross = [col for col in df_cross_border.columns if \"(import)\" in col.lower()]\n",
    "\n",
    "df_cross_border['Total_Exports_cross'] = df_cross_border[export_cols_cross].sum(axis=1)\n",
    "df_cross_border['Total_Imports_cross'] = df_cross_border[import_cols_cross].sum(axis=1)\n",
    "\n",
    "\n",
    "# Merge the Aggregated Columns for Comparison\n",
    "df_flows_extended = pd.merge(\n",
    "    df_scheduled_exchanges[['Total_Exports_scheduled', 'Total_Imports_scheduled']],\n",
    "    df_cross_border[['Total_Exports_cross', 'Total_Imports_cross']],\n",
    "    left_index=True, right_index=True, how='inner'\n",
    ")\n",
    "\n",
    "print(\"Aggregated Exports and Imports (Scheduled vs Cross-Border):\")\n",
    "print(df_flows_extended.head())\n",
    "\n",
    "# =============================================================================\n",
    "# Visualization of Aggregated Exports and Imports\n",
    "# =============================================================================\n",
    "\n",
    "# Time Series Comparison of Exports\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_flows_extended.index, df_flows_extended['Total_Exports_scheduled'], \n",
    "         label='Scheduled Exports', linewidth=2, color='blue')\n",
    "plt.plot(df_flows_extended.index, df_flows_extended['Total_Exports_cross'], \n",
    "         label='Cross-Border Exports', linewidth=2, color='green')\n",
    "plt.title(\"Time Series Comparison of Exports\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Exports (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time Series Comparison of Imports \n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_flows_extended.index, df_flows_extended['Total_Imports_scheduled'], \n",
    "         label='Scheduled Imports', linewidth=2, color='red')\n",
    "plt.plot(df_flows_extended.index, df_flows_extended['Total_Imports_cross'], \n",
    "         label='Cross-Border Imports', linewidth=2, color='orange')\n",
    "plt.title(\"Time Series Comparison of Imports\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Imports (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot - Exports (Scheduled vs. Cross-Border) \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Total_Exports_scheduled', y='Total_Exports_cross', \n",
    "                data=df_flows_extended, color='blue', alpha=0.7)\n",
    "min_exp = df_flows_extended[['Total_Exports_scheduled', 'Total_Exports_cross']].min().min()\n",
    "max_exp = df_flows_extended[['Total_Exports_scheduled', 'Total_Exports_cross']].max().max()\n",
    "plt.plot([min_exp, max_exp], [min_exp, max_exp], color='black', linestyle='--', label='45° Line')\n",
    "plt.title(\"Scatter Plot: Scheduled vs. Cross-Border Exports\")\n",
    "plt.xlabel(\"Scheduled Exports (MWh)\")\n",
    "plt.ylabel(\"Cross-Border Exports (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot - Imports (Scheduled vs. Cross-Border) \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Total_Imports_scheduled', y='Total_Imports_cross', \n",
    "                data=df_flows_extended, color='red', alpha=0.7)\n",
    "min_imp = df_flows_extended[['Total_Imports_scheduled', 'Total_Imports_cross']].min().min()\n",
    "max_imp = df_flows_extended[['Total_Imports_scheduled', 'Total_Imports_cross']].max().max()\n",
    "plt.plot([min_imp, max_imp], [min_imp, max_imp], color='black', linestyle='--', label='45° Line')\n",
    "plt.title(\"Scatter Plot: Scheduled vs. Cross-Border Imports\")\n",
    "plt.xlabel(\"Scheduled Imports (MWh)\")\n",
    "plt.ylabel(\"Cross-Border Imports (MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. CORRELATION & FEATURE RELATIONSHIPS\n",
    "# =============================================================================\n",
    "\n",
    "# Identify features with strongest correlations with day-ahead prices)\n",
    "# For simplicity, I decided to do the correlations using the Germany/Luxembourg day-ahead prices column\n",
    "\n",
    "# Adjust column names as needed for merging; here we assume the indexes align\n",
    "df_corr = pd.DataFrame(index=df_prices.index)\n",
    "df_corr[\"Price_DE_LU\"] = df_prices[\"Germany/Luxembourg [€/MWh]_dayahead\"]\n",
    "\n",
    "# Generation features: Aggregate them.\n",
    "renewable_cols = [\"Biomass [MWh]_actual_gen\", \"Hydropower [MWh]_actual_gen\",\n",
    "                  \"Wind offshore [MWh]_actual_gen\", \"Wind onshore [MWh]_actual_gen\",\n",
    "                  \"Photovoltaics [MWh]_actual_gen\", \"Other renewable [MWh]_actual_gen\"]\n",
    "\n",
    "\n",
    "if all(col in df_actual_gen.columns for col in renewable_cols):\n",
    "    df_corr[\"Total_Renewables\"] = df_actual_gen[renewable_cols].sum(axis=1)\n",
    "else:\n",
    "    print(\"Not all renewable columns found in df_actual_gen.\")\n",
    "\n",
    "conventional_cols = [\"Nuclear [MWh]_actual_gen\", \"Lignite [MWh]_actual_gen\",\n",
    "                     \"Hard coal [MWh]_actual_gen\", \"Fossil gas [MWh]_actual_gen\",\n",
    "                     \"Hydro pumped storage [MWh]_actual_gen\", \"Other conventional [MWh]_actual_gen\"]\n",
    "\n",
    "\n",
    "if all(col in df_actual_gen.columns for col in conventional_cols):\n",
    "    df_corr[\"Total_Conventionals\"] = df_actual_gen[conventional_cols].sum(axis=1)\n",
    "else:\n",
    "    print(\"Not all conventional columns found in df_actual_gen.\")\n",
    "  \n",
    "\n",
    "# Add TSO costs columns (2024)\n",
    "for col in df_costs.columns:\n",
    "    df_corr[col] = df_costs[col]\n",
    "\n",
    "# Add Automatic Frequency Restoration Reserve columns (2023)\n",
    "for col in df_auto_frr.columns:\n",
    "    df_corr[col] = df_auto_frr[col]\n",
    "\n",
    "# Add Frequency Containment Reserve column (2023)\n",
    "for col in df_fcr.columns:\n",
    "    df_corr[col] = df_fcr[col]\n",
    "\n",
    "\n",
    "# Add Scheduled Comercial Exhanges Net export [MWh]_scheduled_exchanges column df_scheduled_exchanges\n",
    "if \"Net export [MWh]_scheduled_exchanges\" in df_scheduled_exchanges.columns:\n",
    "    df_corr[\"Scheduled Exchanges\"] = df_scheduled_exchanges[\"Net export [MWh]_scheduled_exchanges\"]\n",
    "\n",
    "if \"Net export [MWh]_cross_border\" in df_cross_border.columns:\n",
    "    df_corr[\"Cross Border\"] = df_cross_border[\"Net export [MWh]_cross_border\"]\n",
    "\n",
    "# Add Balancing Energy Price\n",
    "if \"Price [€/MWh]_balancing_energy\" in df_balancing_energy.columns:\n",
    "    df_corr[\"Balancing_energy_price\"] = df_balancing_energy[\"Price [€/MWh]_balancing_energy\"]\n",
    "\n",
    "# Drop any rows with missing data (if any) before correlation\n",
    "df_corr_clean = df_corr.dropna()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_corr_clean.corr()\n",
    "\n",
    "# Plot heatmap for correlations\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix: Day-Ahead Price vs. TSO Costs, FRR, FCR, and Balancing Energy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define a correlation threshold (both positive and negative) using absolute correlation\n",
    "corr_threshold = 0.5\n",
    "\n",
    "# Compute correlations between 'Price_DE_LU' and all other features\n",
    "price_corr_series = corr_matrix[\"Price_DE_LU\"].drop(\"Price_DE_LU\")  \n",
    "\n",
    "# Select features that have an absolute correlation above the threshold (this captures both positive and negative)\n",
    "high_corr_features = price_corr_series[price_corr_series.abs() >= corr_threshold]\n",
    "\n",
    "# Sort the results by absolute correlation\n",
    "high_corr_features = high_corr_features.reindex(high_corr_features.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"\\nHighly correlated features with Germany/Luxembourg Day-Ahead Price (|corr| >= {:.2f}):\".format(corr_threshold))\n",
    "print(high_corr_features)\n",
    "\n",
    "\n",
    "# Analyze correlations between prices of different countries\n",
    "price_corr = df_prices[selected_price_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(price_corr, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Inter-Country Day-Ahead Price Correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. PRICE & CONSUMPTION IMPACT ANALYSIS \n",
    "# =============================================================================\n",
    "# This section investigates:\n",
    "#  - How scheduled commercial exchanges influence price fluctuations\n",
    "#  - The impact of cross-border physical flows on day-ahead prices\n",
    "\n",
    "\n",
    "# Merge scheduled commercial exchanges + cross-border flows with DE/LU day-ahead price\n",
    "df_exchanges = pd.DataFrame(index=df_prices.index)\n",
    "\n",
    "for col in df_scheduled_exchanges.columns:\n",
    "    df_exchanges[col] = df_scheduled_exchanges[col]\n",
    "\n",
    "for col in df_cross_border.columns:\n",
    "    df_exchanges[col] = df_cross_border[col]\n",
    "\n",
    "df_exchanges[\"Price_DE_LU\"] = df_prices[\"Germany/Luxembourg [€/MWh]_dayahead\"]\n",
    "\n",
    "# Correlation Analysis (Non-Lagged)\n",
    "df_exchanges_clean = df_exchanges.dropna()\n",
    "corr_matrix_exchanges = df_exchanges_clean.corr()\n",
    "price_corr_exchanges = corr_matrix_exchanges[\"Price_DE_LU\"].drop(\"Price_DE_LU\")\n",
    "\n",
    "# Sort correlations in descending order\n",
    "price_corr_exchanges_sorted = price_corr_exchanges.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nCorrelation with Price_DE_LU (Scheduled Exchanges + Cross-Border Flows):\")\n",
    "print(price_corr_exchanges_sorted)\n",
    "\n",
    "# More readable bar plot\n",
    "# Plot top N features for better legibility\n",
    "top_n = 20\n",
    "top_corr = price_corr_exchanges_sorted.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=top_corr.values, y=top_corr.index, orient='h')\n",
    "plt.title(f\"Top {top_n} Correlations of Exchanges/Flows with DE/LU Day-Ahead Price\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Lag Analysis\n",
    "\n",
    "def create_lagged_dataframe(df, cols, lags=[1, 2, 3, 6, 12]):\n",
    "\n",
    "    lag_data = {}\n",
    "    for col in cols:\n",
    "        for lag in lags:\n",
    "            lag_data[f\"{col}_lag_{lag}h\"] = df[col].shift(lag)\n",
    "    # Combine original and lagged data\n",
    "    df_lagged = pd.concat([df, pd.DataFrame(lag_data, index=df.index)], axis=1)\n",
    "    return df_lagged\n",
    "\n",
    "# Define which columns to lag (all except Price_DE_LU)\n",
    "exchange_cols = [col for col in df_exchanges.columns if col != \"Price_DE_LU\"]\n",
    "df_exchanges_lag = create_lagged_dataframe(df_exchanges, exchange_cols)\n",
    "df_exchanges_lag.dropna(inplace=True)\n",
    "\n",
    "# Compute correlations with Price_DE_LU\n",
    "lag_corr_exchanges = df_exchanges_lag.corr()[\"Price_DE_LU\"].sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nCorrelation of lagged scheduled exchanges & cross-border flows with Day-Ahead Price:\")\n",
    "print(lag_corr_exchanges.head(30))  \n",
    "\n",
    "# Horizontal Bar Plot for Lagged Features\n",
    "# Filter out Price_DE_LU from the index so we don't plot it\n",
    "lag_corr_exchanges_features = lag_corr_exchanges.drop(\"Price_DE_LU\", errors='ignore')\n",
    "\n",
    "# Let's plot the top 20 again for clarity\n",
    "top_lag_n = 20\n",
    "top_lag_corr = lag_corr_exchanges_features.head(top_lag_n)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.barplot(x=top_lag_corr.values, y=top_lag_corr.index, orient='h')\n",
    "plt.title(f\"Top {top_lag_n} Correlations of Lagged Exchanges & Flows with DE/LU Price\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.ylabel(\"Lagged Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Model Pipeline for PowerCast: Electricity Price Forecasting Challenge\n",
    "# =============================================================================\n",
    "#  Important Note: If using this section as a .py script, don't forget to import \n",
    "#  the libraries and set the files path to be able to upload the files.\n",
    "#\n",
    "#  - Additional temporal features (day-of-week, hour-of-day with cyclical encoding)\n",
    "#  - Advanced feature engineering \n",
    "#  - Outlier detection using IQR\n",
    "#  - Linear Regression\n",
    "#  - Random Forest,\n",
    "#  - Scikit-learn GradientBoostingRegressor for quantile regression \n",
    "#    with post-hoc calibration\n",
    "#  - Interpretability via SHAP\n",
    "#\n",
    "# Packages: pandas, numpy, matplotlib, seaborn, scikit-learn,\n",
    "#                    shap, scipy\n",
    "# =============================================================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 7)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def load_file(file_path, date_col='Date'):\n",
    "    \"\"\"Load an Excel file, parse date, and set as index.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df.set_index(date_col, inplace=True)\n",
    "    return df\n",
    "\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"Calculate percentage of times the predicted direction matches actual direction.\"\"\"\n",
    "    y_true, y_pred = y_true.align(y_pred, join='inner')\n",
    "    true_change = y_true.diff().dropna()\n",
    "    pred_change = y_pred.diff().dropna()\n",
    "    true_sign = np.sign(true_change)\n",
    "    pred_sign = np.sign(pred_change)\n",
    "    correct = (true_sign == pred_sign).sum()\n",
    "    total = len(true_sign)\n",
    "    return correct / total if total > 0 else np.nan\n",
    "\n",
    "def volatility_capture(y_true, y_pred):\n",
    "    \"\"\"Compute ratio of std of predicted returns to actual returns.\"\"\"\n",
    "    y_true, y_pred = y_true.align(y_pred, join='inner')\n",
    "    true_returns = y_true.diff().dropna()\n",
    "    pred_returns = y_pred.diff().dropna()\n",
    "    std_true = np.std(true_returns)\n",
    "    std_pred = np.std(pred_returns)\n",
    "    return std_pred / std_true if std_true != 0 else np.nan\n",
    "\n",
    "def extreme_price_movement_detection(y_true, y_pred, threshold=0.15):\n",
    "    \"\"\"Compute precision and recall for detecting extreme price changes (> threshold).\"\"\"\n",
    "    y_true, y_pred = y_true.align(y_pred, join='inner')\n",
    "    true_pct_change = y_true.pct_change().dropna()\n",
    "    pred_pct_change = y_pred.pct_change().dropna()\n",
    "    true_extreme = (true_pct_change.abs() > threshold).astype(int)\n",
    "    pred_extreme = (pred_pct_change.abs() > threshold).astype(int)\n",
    "    TP = ((true_extreme == 1) & (pred_extreme == 1)).sum()\n",
    "    FP = ((true_extreme == 0) & (pred_extreme == 1)).sum()\n",
    "    FN = ((true_extreme == 1) & (pred_extreme == 0)).sum()\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    return precision, recall\n",
    "\n",
    "def create_lagged_features(df, columns, lags=[1, 2, 3, 6, 12]):\n",
    "    df_lagged = df.copy()\n",
    "    for col in columns:\n",
    "        for lag in lags:\n",
    "            df_lagged[f\"{col}_lag_{lag}h\"] = df_lagged[col].shift(lag)\n",
    "    return df_lagged\n",
    "\n",
    "def add_rolling_features(df, col, windows=[6, 12, 24]):\n",
    "    for w in windows:\n",
    "        df[f\"{col}_rolling_mean_{w}h\"] = df[col].rolling(w).mean()\n",
    "        df[f\"{col}_rolling_std_{w}h\"] = df[col].rolling(w).std()\n",
    "    return df\n",
    "\n",
    "def persistence_forecast(train_y, test_y):\n",
    "    \"\"\"Naive forecast: next value equals previous value (fallback uses last training value).\"\"\"\n",
    "    y_pred = test_y.shift(1)\n",
    "    if len(y_pred) > 0:\n",
    "        y_pred.iloc[0] = train_y.iloc[-1]\n",
    "    return y_pred\n",
    "\n",
    "def remove_outliers_iqr(df, col, multiplier=1.5):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    df = df.copy()\n",
    "    # Ensure the index is a DatetimeIndex\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['hour_of_day'] = df.index.hour\n",
    "    # Cyclical encoding: hour_of_day\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
    "    # Cyclical encoding: day_of_week\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    return df\n",
    "\n",
    "def calibrate_intervals(y_true, lower, upper, target_coverage=0.95):\n",
    "    \"\"\"\n",
    "    Compute current coverage and return scaling factor.\n",
    "    Scale factor = target_coverage / current_coverage (if current_coverage > 0).\n",
    "    \"\"\"\n",
    "    current_coverage = ((y_true >= lower) & (y_true <= upper)).mean()\n",
    "    print(f\"Current coverage: {current_coverage:.2%}\")\n",
    "    factor = target_coverage / current_coverage if current_coverage > 0 else 1.0\n",
    "    return factor\n",
    "\n",
    "# =============================================================================\n",
    "# 2. MERGE INTO A MODELING DATAFRAME \n",
    "# =============================================================================\n",
    "model_df = pd.DataFrame(index=df_prices.index)\n",
    "model_df[\"Price_DE_LU\"] = df_prices[\"Germany/Luxembourg [€/MWh]_dayahead\"]\n",
    "\n",
    "# Consumption features\n",
    "if \"Total (grid load) [MWh]_actual_cons\" in df_actual_cons.columns:\n",
    "    model_df[\"Actual_cons\"] = df_actual_cons[\"Total (grid load) [MWh]_actual_cons\"]\n",
    "if \"Residual load [MWh]_actual_cons\" in df_actual_cons.columns:\n",
    "    model_df[\"Residual_load\"] = df_actual_cons[\"Residual load [MWh]_actual_cons\"]\n",
    "if \"Total (grid load) [MWh]_forecast_cons\" in df_forecast_cons.columns:\n",
    "    model_df[\"Forecast_cons\"] = df_forecast_cons[\"Total (grid load) [MWh]_forecast_cons\"]\n",
    "\n",
    "# Generation features: Aggregate to macro-level\n",
    "renewable_cols = [\"Biomass [MWh]_actual_gen\", \"Hydropower [MWh]_actual_gen\",\n",
    "                  \"Wind offshore [MWh]_actual_gen\", \"Wind onshore [MWh]_actual_gen\",\n",
    "                  \"Photovoltaics [MWh]_actual_gen\", \"Other renewable [MWh]_actual_gen\"]\n",
    "if all(col in df_actual_gen.columns for col in renewable_cols):\n",
    "    model_df[\"Total_Renewables\"] = df_actual_gen[renewable_cols].sum(axis=1)\n",
    "\n",
    "conventional_cols = [\"Nuclear [MWh]_actual_gen\", \"Lignite [MWh]_actual_gen\",\n",
    "                     \"Hard coal [MWh]_actual_gen\", \"Fossil gas [MWh]_actual_gen\",\n",
    "                     \"Hydro pumped storage [MWh]_actual_gen\", \"Other conventional [MWh]_actual_gen\"]\n",
    "if all(col in df_actual_gen.columns for col in conventional_cols):\n",
    "    model_df[\"Total_Conventionals\"] = df_actual_gen[conventional_cols].sum(axis=1)\n",
    "\n",
    "# Net export features\n",
    "if \"Net export [MWh]_cross_border\" in df_cross_border.columns:\n",
    "    model_df[\"Net_export_physical\"] = df_cross_border[\"Net export [MWh]_cross_border\"]\n",
    "if \"Net export [MWh]_scheduled_exchanges\" in df_scheduled_exchanges.columns:\n",
    "    model_df[\"Net_export_scheduled\"] = df_scheduled_exchanges[\"Net export [MWh]_scheduled_exchanges\"]\n",
    "\n",
    "# Add temporal features \n",
    "model_df = add_temporal_features(model_df)\n",
    "\n",
    "# =============================================================================\n",
    "# 3 OUTLIER DETECTION: Cap outliers using IQR for each column\n",
    "# =============================================================================\n",
    "for col in model_df.columns:\n",
    "    model_df = remove_outliers_iqr(model_df, col)\n",
    "model_df.dropna(inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ADVANCED FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "# Add rolling features\n",
    "model_df = add_rolling_features(model_df, \"Residual_load\", windows=[6, 12, 24])\n",
    "model_df = add_rolling_features(model_df, \"Net_export_physical\", windows=[6, 12])\n",
    "model_df.dropna(inplace=True)\n",
    "\n",
    "# Add lagged features for selected variables\n",
    "lag_columns = [\"Actual_cons\", \"Residual_load\", \"Forecast_cons\", \"Total_Renewables\", \n",
    "               \"Total_Conventionals\", \"Net_export_physical\", \"Net_export_scheduled\", \n",
    "               \"day_of_week\", \"hour_of_day\", \"hour_sin\", \"hour_cos\", \"dow_sin\", \"dow_cos\"]\n",
    "model_df_lagged = create_lagged_features(model_df, lag_columns, lags=[1, 2, 3, 6, 12])\n",
    "model_df_lagged.dropna(inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. TRAIN/TEST SPLIT (80/20)\n",
    "# =============================================================================\n",
    "\n",
    "total_samples = len(model_df_lagged)\n",
    "split_index = int(total_samples * 0.8)\n",
    "\n",
    "train_df = model_df_lagged.iloc[:split_index].copy()\n",
    "test_df  = model_df_lagged.iloc[split_index:].copy()\n",
    "\n",
    "target_col = \"Price_DE_LU\"\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "X_test  = test_df.drop(columns=[target_col])\n",
    "y_test  = test_df[target_col]\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. BASELINE MODEL: PERSISTENCE\n",
    "# =============================================================================\n",
    "\n",
    "y_pred_persistence = persistence_forecast(y_train, y_test)\n",
    "\n",
    "rmse_pers = sqrt(mean_squared_error(y_test, y_pred_persistence))\n",
    "mae_pers  = mean_absolute_error(y_test, y_pred_persistence)\n",
    "dir_acc_pers = directional_accuracy(y_test, y_pred_persistence)\n",
    "vol_cap_pers = volatility_capture(y_test, y_pred_persistence)\n",
    "prec_ext_pers, rec_ext_pers = extreme_price_movement_detection(y_test, y_pred_persistence)\n",
    "\n",
    "print(\"\\n=== BASELINE (Persistence) ===\")\n",
    "print(f\"RMSE: {rmse_pers:.2f}\")\n",
    "print(f\"MAE:  {mae_pers:.2f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_pers:.2%}\")\n",
    "print(f\"Volatility Capture (ratio): {vol_cap_pers:.2f}\")\n",
    "print(f\"Extreme Movement Detection (Precision/Recall): {prec_ext_pers:.2f} / {rec_ext_pers:.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. LINEAR REGRESSION\n",
    "# =============================================================================\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred_lin = linreg.predict(X_test)\n",
    "\n",
    "rmse_lin = sqrt(mean_squared_error(y_test, y_pred_lin))\n",
    "mae_lin  = mean_absolute_error(y_test, y_pred_lin)\n",
    "dir_acc_lin = directional_accuracy(y_test, pd.Series(y_pred_lin, index=y_test.index))\n",
    "vol_cap_lin = volatility_capture(y_test, pd.Series(y_pred_lin, index=y_test.index))\n",
    "prec_ext_lin, rec_ext_lin = extreme_price_movement_detection(y_test, pd.Series(y_pred_lin, index=y_test.index))\n",
    "\n",
    "print(\"\\n=== LINEAR REGRESSION ===\")\n",
    "print(f\"RMSE: {rmse_lin:.2f}\")\n",
    "print(f\"MAE:  {mae_lin:.2f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_lin:.2%}\")\n",
    "print(f\"Volatility Capture (ratio): {vol_cap_lin:.2f}\")\n",
    "print(f\"Extreme Movement Detection (Precision/Recall): {prec_ext_lin:.2f} / {rec_ext_lin:.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Random Forest\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': randint(2, 15),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=30,  # expanded iterations\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=tscv,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "print(\"Best params for Random Forest:\", random_search_rf.best_params_)\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "y_pred_rf_tuned = best_rf.predict(X_test)\n",
    "\n",
    "rmse_rf = sqrt(mean_squared_error(y_test, y_pred_rf_tuned))\n",
    "mae_rf  = mean_absolute_error(y_test, y_pred_rf_tuned)\n",
    "dir_acc_rf = directional_accuracy(y_test, pd.Series(y_pred_rf_tuned, index=y_test.index))\n",
    "vol_cap_rf = volatility_capture(y_test, pd.Series(y_pred_rf_tuned, index=y_test.index))\n",
    "prec_ext_rf, rec_ext_rf = extreme_price_movement_detection(y_test, pd.Series(y_pred_rf_tuned, index=y_test.index))\n",
    "\n",
    "print(\"\\n=== TUNED RANDOM FOREST ===\")\n",
    "print(f\"RMSE: {rmse_rf:.2f}\")\n",
    "print(f\"MAE:  {mae_rf:.2f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_rf:.2%}\")\n",
    "print(f\"Volatility Capture (ratio): {vol_cap_rf:.2f}\")\n",
    "print(f\"Extreme Movement Detection (Precision/Recall): {prec_ext_rf:.2f} / {rec_ext_rf:.2f}\")\n",
    "\n",
    "\n",
    "# ============================================================================================\n",
    "# 09. Quantile Regression (GradientBoostingRegressor) & Post-Hoc Calibration\n",
    "# ============================================================================================\n",
    "\n",
    "print(\"\\nTuning scikit-learn GradientBoostingRegressor for 95% prediction interval...\")\n",
    "\n",
    "# Train the model for the 5th percentile (lower bound)\n",
    "gbr_lower = GradientBoostingRegressor(loss='quantile', alpha=0.05, \n",
    "                                      n_estimators=500, learning_rate=0.1, \n",
    "                                      max_depth=3, random_state=42)\n",
    "gbr_lower.fit(X_train, y_train)\n",
    "y_pred_lower = gbr_lower.predict(X_test)\n",
    "\n",
    "# Train the model for the 95th percentile (upper bound)\n",
    "gbr_upper = GradientBoostingRegressor(loss='quantile', alpha=0.95, \n",
    "                                      n_estimators=500, learning_rate=0.1, \n",
    "                                      max_depth=3, random_state=42)\n",
    "gbr_upper.fit(X_train, y_train)\n",
    "y_pred_upper = gbr_upper.predict(X_test)\n",
    "\n",
    "coverage = ((y_test >= y_pred_lower) & (y_test <= y_pred_upper)).mean()\n",
    "print(f\"Initial Coverage of 95% prediction interval: {coverage:.2%}\")\n",
    "\n",
    "# Post-Hoc Calibration: If coverage is below 95%, scale the interval width.\n",
    "def calibrate_intervals(y_true, lower, upper, target_coverage=0.95):\n",
    "    current_coverage = ((y_true >= lower) & (y_true <= upper)).mean()\n",
    "    print(f\"Current coverage before calibration: {current_coverage:.2%}\")\n",
    "    factor = target_coverage / current_coverage if current_coverage > 0 else 1.0\n",
    "    return factor\n",
    "\n",
    "# Use a validation set for calibration\n",
    "scale_factor = calibrate_intervals(y_test, y_pred_lower, y_pred_upper, target_coverage=0.95)\n",
    "print(f\"Scaling factor for intervals: {scale_factor:.2f}\")\n",
    "\n",
    "interval_mid = (y_pred_lower + y_pred_upper) / 2.0\n",
    "interval_half_width = (y_pred_upper - y_pred_lower) / 2.0\n",
    "y_pred_lower_cal = interval_mid - scale_factor * interval_half_width\n",
    "y_pred_upper_cal = interval_mid + scale_factor * interval_half_width\n",
    "\n",
    "coverage_cal = ((y_test >= y_pred_lower_cal) & (y_test <= y_pred_upper_cal)).mean()\n",
    "print(f\"Calibrated Coverage of 95% prediction interval: {coverage_cal:.2%}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.index, y_test, label=\"Actual Price\", color=\"black\", linewidth=1.5)\n",
    "plt.plot(y_test.index, (y_pred_lower_cal + y_pred_upper_cal) / 2, label=\"Calibrated Median\", color=\"blue\")\n",
    "plt.fill_between(y_test.index, y_pred_lower_cal, y_pred_upper_cal, color=\"gray\", alpha=0.3,\n",
    "                 label=\"Calibrated 95% Prediction Interval\")\n",
    "plt.title(\"Calibrated GradientBoostingRegressor Prediction Intervals\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. Interpretability with SHAP (For Random Forest)\n",
    "# =============================================================================\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\" # set the number of threads that you want\n",
    "shap_cache_file = \"shap_values_rf.pkl\"\n",
    "\n",
    "if os.path.exists(shap_cache_file):\n",
    "    os.remove(shap_cache_file)\n",
    "    print(\"Deleted old SHAP cache file. Recomputing SHAP values...\")\n",
    "\n",
    "# We can sample if X_test is very large:\n",
    "X_test_sample = X_test\n",
    "\n",
    "# Check for additional columns in X_test_sample\n",
    "extra_columns = set(X_test_sample.columns) - set(X_train.columns)\n",
    "if extra_columns:\n",
    "    print(\"Warning: X_test_sample contains additional columns not in X_train:\")\n",
    "    print(sorted(extra_columns))\n",
    "\n",
    "# Compute or load SHAP values\n",
    "if os.path.exists(shap_cache_file):\n",
    "    with open(shap_cache_file, \"rb\") as f:\n",
    "        shap_values_rf = pickle.load(f)\n",
    "    print(\"Loaded SHAP values from cache.\")\n",
    "else:\n",
    "    explainer_rf = shap.TreeExplainer(best_rf)\n",
    "    shap_values_rf = explainer_rf.shap_values(X_test_sample)\n",
    "    with open(shap_cache_file, \"wb\") as f:\n",
    "        pickle.dump(shap_values_rf, f)\n",
    "    print(\"Computed and cached SHAP values.\")\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_values_rf, X_test_sample, plot_type=\"bar\", max_display=10, show=False)\n",
    "plt.title(\"Random Forest Feature Importance (Top 10 via SHAP)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot SHAP summary \n",
    "shap.summary_plot(shap_values_rf, X_test_sample, max_display=10, show=False)\n",
    "plt.title(\"Random Forest Detailed SHAP Summary (Top 10)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. Evaluation\n",
    "# =============================================================================\n",
    "\n",
    "results = [\n",
    "    (\"Persistence\", rmse_pers, mae_pers, dir_acc_pers, vol_cap_pers, prec_ext_pers, rec_ext_pers),\n",
    "    (\"LinearReg\", rmse_lin, mae_lin, dir_acc_lin, vol_cap_lin, prec_ext_lin, rec_ext_lin),\n",
    "    (\"RandomForest\", rmse_rf, mae_rf, dir_acc_rf, vol_cap_rf, prec_ext_rf, rec_ext_rf),\n",
    "\n",
    "]\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"Model\", \"RMSE\", \"MAE\", \"Directional_Accuracy\", \"Volatility_Capture\",\n",
    "    \"Extreme_Precision\", \"Extreme_Recall\"\n",
    "])\n",
    "print(\"\\n=== FINAL RESULTS SUMMARY ===\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.plot(x=\"Model\", y=[\"RMSE\", \"MAE\"], kind=\"bar\", figsize=(10, 5),\n",
    "                title=\"Error Metrics by Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScript Complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
